{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f943e6-b780-4919-9f93-51d5b2a1da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB as MB\n",
    "from sklearn.naive_bayes import GaussianNB as GB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba1e45e-ec18-488f-a8e5-0bdf546d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\bhimr\\\\Downloads\\\\blogs (1).csv\")\n",
    "data.to_csv(\"C:\\\\Users\\\\bhimr\\\\Downloads\\\\blogs_no_header.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203f7e37-473f-4d27-b819-318c5040ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data       Labels\n",
       "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
       "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
       "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81486e97-c7de-4a18-9db7-7a3a10463d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54fcc19f-a7a7-4b46-a98c-e99c2cfc7db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data      0\n",
       "Labels    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41413b67-098c-4477-8b6d-70aa707c7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Text\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation, and remove words containing numbers.'''\n",
    "    import re\n",
    "    import string\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Raw string to handle special characters\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Removes words with numbers\n",
    "    text = re.sub(r'[0-9]+', ' ', text)\n",
    "    text = re.sub(r'[‘’“”…]', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226cf52b-ec2f-42d5-aa4f-628273061fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     23314\n",
       "to      12877\n",
       "of      12222\n",
       "a       10312\n",
       "and      9916\n",
       "I        7417\n",
       "is       7235\n",
       "in       6962\n",
       "that     6443\n",
       ">        5075\n",
       "for      4645\n",
       "you      3855\n",
       "it       3645\n",
       "on       3512\n",
       "be       3274\n",
       "have     3096\n",
       "with     3017\n",
       "are      2927\n",
       "not      2881\n",
       "The      2576\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(data['Data']).split()).value_counts()[:20]\n",
    "freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbc4e59-bb8f-481f-821e-3d66d90e1318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I                7417\n",
       ">                5075\n",
       "The              2576\n",
       "Subject:         2056\n",
       "From:            2033\n",
       "Newsgroups:      2011\n",
       "Date:            2008\n",
       "Path:            2003\n",
       "Message-ID:      2003\n",
       "Lines:           1998\n",
       "Organization:    1937\n",
       "Apr              1937\n",
       "GMT              1785\n",
       "|                1641\n",
       "-                1595\n",
       "In               1495\n",
       "would            1485\n",
       "writes:          1452\n",
       "--               1422\n",
       "1993             1403\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Stop Words\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['Data'] = data['Data'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "freq_Sw = pd.Series(' '.join(data['Data']).split()).value_counts()[:20]\n",
    "freq_Sw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab2bde06-1988-47da-8efe-c72f7ff2c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>339</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>103</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000001200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000005102000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00000510200001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00000f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000036</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000050</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000ahc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000vec</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00014211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000152</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000216</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000256</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000345edt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00044808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0005111312</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0005111312na1em</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0005111312na3em</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0005169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000601</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term  occurrences  frequency\n",
       "0                00          339   0.000687\n",
       "1               000          103   0.000209\n",
       "2              0000            5   0.000010\n",
       "3             00000            1   0.000002\n",
       "4        0000001200            1   0.000002\n",
       "5            000003            1   0.000002\n",
       "6      000005102000            2   0.000004\n",
       "7    00000510200001            1   0.000002\n",
       "8            00000f            1   0.000002\n",
       "9            000036            1   0.000002\n",
       "10           000050            3   0.000006\n",
       "11          0000ahc            1   0.000002\n",
       "12          0000vec            2   0.000004\n",
       "13             0001            7   0.000014\n",
       "14         00014211            1   0.000002\n",
       "15           000152            3   0.000006\n",
       "16             0002            1   0.000002\n",
       "17           000211            1   0.000002\n",
       "18           000216            1   0.000002\n",
       "19           000256            2   0.000004\n",
       "20        000345edt            1   0.000002\n",
       "21           000417            1   0.000002\n",
       "22         00044808            1   0.000002\n",
       "23             0005            1   0.000002\n",
       "24       0005111312            2   0.000004\n",
       "25  0005111312na1em            3   0.000006\n",
       "26  0005111312na3em            2   0.000004\n",
       "27          0005169            1   0.000002\n",
       "28           000601            2   0.000004\n",
       "29           000710            1   0.000002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1, max_df=0.9)\n",
    "X = vectorizer.fit_transform(data[\"Data\"])\n",
    "#Creating a DataFrame fro word frequencies\n",
    "word_freq_df = pd.DataFrame({'term': vectorizer.get_feature_names_out(), \n",
    "                             'occurrences': np.asarray(X.sum(axis=0)).ravel().tolist()})\n",
    "#Calculate word Frequencies\n",
    "word_freq_df['frequency'] = word_freq_df['occurrences'] / np.sum(word_freq_df['occurrences'])\n",
    "word_freq_df.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd254878-aa13-47c2-96ed-cd94dbdca475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>x11</th>\n",
       "      <th>x11r5</th>\n",
       "      <th>xref</th>\n",
       "      <th>yale</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zaphod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020147</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026296</td>\n",
       "      <td>0.062288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.038528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            00       000   01        02   03   04   05   06        07  \\\n",
       "0     0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "1     0.000000  0.000000  0.0  0.120197  0.0  0.0  0.0  0.0  0.000000   \n",
       "2     0.000000  0.000000  0.0  0.063697  0.0  0.0  0.0  0.0  0.000000   \n",
       "3     0.000000  0.026673  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "4     0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "...        ...       ...  ...       ...  ...  ...  ...  ...       ...   \n",
       "1995  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "1996  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "1997  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.076426   \n",
       "1998  0.000000  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "1999  0.038528  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  0.000000   \n",
       "\n",
       "            08  ...  x11  x11r5      xref  yale      year     years       yes  \\\n",
       "0     0.000000  ...  0.0    0.0  0.000000   0.0  0.000000  0.000000  0.036175   \n",
       "1     0.000000  ...  0.0    0.0  0.000000   0.0  0.000000  0.000000  0.000000   \n",
       "2     0.000000  ...  0.0    0.0  0.000000   0.0  0.000000  0.000000  0.000000   \n",
       "3     0.000000  ...  0.0    0.0  0.000000   0.0  0.020147  0.018728  0.133085   \n",
       "4     0.049562  ...  0.0    0.0  0.030010   0.0  0.000000  0.041513  0.000000   \n",
       "...        ...  ...  ...    ...       ...   ...       ...       ...       ...   \n",
       "1995  0.000000  ...  0.0    0.0  0.019009   0.0  0.000000  0.026296  0.062288   \n",
       "1996  0.000000  ...  0.0    0.0  0.034911   0.0  0.000000  0.000000  0.000000   \n",
       "1997  0.000000  ...  0.0    0.0  0.045707   0.0  0.000000  0.000000  0.000000   \n",
       "1998  0.000000  ...  0.0    0.0  0.043446   0.0  0.000000  0.000000  0.000000   \n",
       "1999  0.000000  ...  0.0    0.0  0.027815   0.0  0.000000  0.000000  0.000000   \n",
       "\n",
       "      york  young    zaphod  \n",
       "0      0.0    0.0  0.018811  \n",
       "1      0.0    0.0  0.070080  \n",
       "2      0.0    0.0  0.000000  \n",
       "3      0.0    0.0  0.000000  \n",
       "4      0.0    0.0  0.025566  \n",
       "...    ...    ...       ...  \n",
       "1995   0.0    0.0  0.016194  \n",
       "1996   0.0    0.0  0.000000  \n",
       "1997   0.0    0.0  0.038939  \n",
       "1998   0.0    0.0  0.000000  \n",
       "1999   0.0    0.0  0.000000  \n",
       "\n",
       "[2000 rows x 1000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing TfidVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.5)\n",
    "doc_vec = vectorizer.fit_transform(data[\"Data\"])\n",
    "\n",
    "df = pd.DataFrame(doc_vec.todense(), columns=vectorizer.get_feature_names_out())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b240fb-d12a-4b32-b29e-eb24c12ba2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bi-gram</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cmu edu</td>\n",
       "      <td>5206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs cmu</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>srv cs</td>\n",
       "      <td>3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cantaloupe srv</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>message id</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bi-gram  Freq\n",
       "0         cmu edu  5206\n",
       "1          cs cmu  3250\n",
       "2          srv cs  3185\n",
       "3  cantaloupe srv  2574\n",
       "4      message id  2007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting top n words from the word corpus\n",
    "def get_top_n2_words(corpus, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=(2, 2), max_features=2000).fit(corpus)\n",
    "    bag_of_words = vec1.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec1.vocabulary_.items()]\n",
    "    return sorted(words_freq, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "top2_df = pd.DataFrame(get_top_n2_words(data[\"Data\"], n=200), columns=[\"Bi-gram\", \"Freq\"])\n",
    "\n",
    "top2_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef17b50-e6c8-44ea-b9c7-700c06d73981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ebcd4-d7c0-4596-9e1f-fb73345705e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the word Count\n",
    "wordcloud_stw = WordCloud(background_color='black', width=1800, height=1500).generate(\" \".join(data[\"Data\"]))\n",
    "plt.imshow(wordcloud_stw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa7c15-9f7a-4b5c-b44d-438a9112a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_train, blog_test = train_test_split(data, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9110af1-edbe-46b3-8656-35770774cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split_into_words function\n",
    "def split_into_words(i):\n",
    "    return (i.split(\" \"))\n",
    "\n",
    "# Now use it in CountVectorizer\n",
    "blog_bow = CountVectorizer(analyzer=split_into_words).fit(data.Data)\n",
    "train_blog_matrix = blog_bow.transform(blog_train.Data)\n",
    "test_blog_matrix = blog_bow.transform(blog_test.Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7501d-4b0c-4a57-8f03-13bae57326b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_mb = MB()\n",
    "classifier_mb.fit(train_blog_matrix, blog_train.Labels)\n",
    "test_pred_m = classifier_mb.predict(test_blog_matrix)\n",
    "accuracy_test_m = np.mean(test_pred_m == blog_test.Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a829c635-5415-4329-b5c3-fee0c35442f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_pred_m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332900e4-e6ae-42cd-a05e-c44cf32be678",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fea2a-01dd-42a7-9a68-005d0d03a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gaussian Naive Bayes model\n",
    "classifier_gb = GB()\n",
    "classifier_gb.fit(train_blog_matrix.toarray(), blog_train.Labels.values)\n",
    "# Predict on the test data\n",
    "test_pred_g = classifier_gb.predict(test_blog_matrix.toarray())\n",
    "# Evaluate accuracy\n",
    "accuracy_test_g = np.mean(test_pred_g == blog_test.Labels)\n",
    "print(\"Test Accuracy (Gaussian Naive Bayes):\", accuracy_test_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbea21-6a05-4bbb-b750-dcb4c1d67fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b904d2-d9b9-47c0-afe6-6bd0e44e04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify sentiment\n",
    "def get_sentiment(text):\n",
    "    '''Returns 'Positive', 'Negative', or 'Neutral' based on the sentiment polarity of the text.'''\n",
    "    sentiment = TextBlob(text).sentiment.polarity  # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "    if sentiment > 0:\n",
    "        return 'Positive'\n",
    "    elif sentiment < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment classification\n",
    "data['sentiment'] = data['Data'].apply(get_sentiment)\n",
    "\n",
    "# Show the first few rows with the sentiment classification\n",
    "print(data[['Data', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9156a4b-6154-478d-a870-3edb1c0da4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=data, palette='viridis')\n",
    "plt.title('Sentiment Distribution in Emails')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de2bf5-86a2-44d7-9209-85dce282508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(blog_test.Labels, test_pred_m)\n",
    "# Plot confusion matrix as a heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=blog_test['Labels'].unique(), yticklabels=blog_test['Labels'].unique())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66424f-4785-4934-8d1b-d3408cd8711f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
